{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LFW_face.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# creat model"
      ],
      "metadata": {
        "id": "5Td9PcBEiS0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "y-lluWg-Hm9f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creat embedding layer"
      ],
      "metadata": {
        "id": "oj5kiXd-iXKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embedding(): \n",
        "    inp = Input(shape=(100,100,3), name='input_image')\n",
        "    \n",
        "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "    \n",
        "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "    \n",
        "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
        "    \n",
        "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "    \n",
        "    \n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
      ],
      "metadata": {
        "id": "b606FRMJHS4o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = make_embedding()"
      ],
      "metadata": {
        "id": "yQ6k63Y5ISF0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class L1Dist(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)"
      ],
      "metadata": {
        "id": "IEK2YCFxHuzG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_siamese_model(): \n",
        "    input_image = Input(name='input_img', shape=(100,100,3))\n",
        "    validation_image = Input(name='validation_img', shape=(100,100,3))\n",
        "    siamese_layer = L1Dist()\n",
        "    siamese_layer._name = 'distance'\n",
        "    distances = siamese_layer(embedding(input_image), embedding(validation_image))\n",
        "    classifier = Dense(1, activation='sigmoid')(distances)\n",
        "    \n",
        "    return Model(inputs=[input_image, validation_image], outputs=classifier, name='SiameseNetwork')"
      ],
      "metadata": {
        "id": "EwozQv45Hz22"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model = make_siamese_model()\n",
        "siamese_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-NnCiGuHwxz",
        "outputId": "527d6391-be20-458e-8953-78c1e808f9e8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"SiameseNetwork\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_img (InputLayer)         [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " validation_img (InputLayer)    [(None, 100, 100, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " embedding (Functional)         (None, 4096)         38960448    ['input_img[0][0]',              \n",
            "                                                                  'validation_img[0][0]']         \n",
            "                                                                                                  \n",
            " distance (L1Dist)              (None, 4096)         0           ['embedding[0][0]',              \n",
            "                                                                  'embedding[1][0]']              \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 1)            4097        ['distance[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,964,545\n",
            "Trainable params: 38,964,545\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# load and prepeocess data"
      ],
      "metadata": {
        "id": "OM3U33hDoJ26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import random \n",
        "import matplotlib.pyplot as plt \n",
        "import os "
      ],
      "metadata": {
        "id": "yk2g4wl5nDYh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/drive/MyDrive/faceR'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58CSyD41ph9S",
        "outputId": "5fb91234-61b5-41c5-a3a1-5d048604b97a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/faceR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Neg_path=os.path.join('data','negative')\n",
        "Pos_path=os.path.join('data','positive')\n",
        "Anc_path=os.path.join('data','anchor')"
      ],
      "metadata": {
        "id": "zcNFY_Ouptam"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(Neg_path)\n",
        "os.makedirs(Pos_path)\n",
        "os.makedirs(Anc_path)"
      ],
      "metadata": {
        "id": "T7fUGTdEpuFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for directory in os.listdir('lfw'):\n",
        "  for files in os.listdir(os.path.join('lfw',directory)):\n",
        "    Ex_path=os.path.join('lfw',directory,files)\n",
        "    New_path= os.path.join(Neg_path, files)\n",
        "    os.replace(Ex_path,New_path)"
      ],
      "metadata": {
        "id": "xgP3RLCRpxHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid"
      ],
      "metadata": {
        "id": "2_clNwUGpzVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cam=cv2.VideoCapture(0)\n",
        "while True:\n",
        "    _,frame=cam.read()\n",
        "    frame=cv2.flip(frame,1)\n",
        "    frame = frame[120:120+250,200:200+250, :]\n",
        "    if cv2.waitKey(1)& 0XFF ==ord('p'):\n",
        "        image_name=os.path.join(Pos_path,'{}.jpg'.format(uuid.uuid1()))\n",
        "        cv2.imwrite(image_name,frame)\n",
        "    \n",
        "    if cv2.waitKey(1)& 0XFF ==ord('a'):\n",
        "        image_name=os.path.join(Anc_path,'{}.jpg'.format(uuid.uuid1()))\n",
        "        cv2.imwrite(image_name,frame)\n",
        "    \n",
        "    cv2.imshow('fram',frame)\n",
        "    if cv2.waitKey(1)& 0XFF ==27:\n",
        "        break"
      ],
      "metadata": {
        "id": "qLd125Bhp4Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "creat helper fuction "
      ],
      "metadata": {
        "id": "B4SUBnVdlbxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(image):\n",
        "  image=(image/127.5)-1\n",
        "  return image\n",
        "def resize(image,height,width):\n",
        "  image=tf.image.resize(image,(height,width),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return image\n",
        "\n",
        "def load_image(image_path):\n",
        "  image=tf.io.read_file(image_path)\n",
        "  image=tf.image.decode_jpeg(image,3)\n",
        "  image=tf.cast(image,tf.float32)\n",
        "  image=resize(image,100,100)\n",
        "  image=normalize(image)\n",
        "  return image \n"
      ],
      "metadata": {
        "id": "BxQ5_MnnqBuV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_anchor_positive_with_label(image_path,positive_path):\n",
        "  anchor=load_image(image_path)\n",
        "  positive=load_image(positive_path)\n",
        "  label=tf.ones(1)\n",
        "  return anchor , positive , label\n",
        "\n",
        "def load_anchor_negative_with_label(image_path,negative_path):\n",
        "  anchor=load_image(image_path)\n",
        "  negative=load_image(negative_path)\n",
        "  label=tf.zeros(1)\n",
        "  return anchor , negative , label"
      ],
      "metadata": {
        "id": "jUYPLRS5rzxj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anchor=tf.data.Dataset.list_files(Anc_path+'/*.jpg').take(300)\n",
        "positive=tf.data.Dataset.list_files(Pos_path+'/*.jpg').take(300)\n",
        "negative=tf.data.Dataset.list_files(Neg_path+'/*.jpg').take(300)"
      ],
      "metadata": {
        "id": "z3EwRKHHp8p9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anc_pos=tf.data.Dataset.zip((anchor,positive))\n",
        "anc_neg=tf.data.Dataset.zip((anchor,negative))"
      ],
      "metadata": {
        "id": "acUOpLzgsnmH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "anc_pos_data=anc_pos.map(load_anchor_positive_with_label)\n",
        "anc_neg_data=anc_neg.map(load_anchor_negative_with_label)"
      ],
      "metadata": {
        "id": "486LGd7ourfg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = anc_pos_data.concatenate(anc_neg_data)"
      ],
      "metadata": {
        "id": "tF9n5OpJu2UT"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.shuffle(1000)\n",
        "train_data = data.take(round(len(data)*.7))\n",
        "train_data = train_data.batch(16)"
      ],
      "metadata": {
        "id": "B0KS6Tz7vWIz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data.skip(round(len(data)*.7))\n",
        "test_data = test_data.take(round(len(data)*.3))\n",
        "test_data = test_data.batch(16)"
      ],
      "metadata": {
        "id": "EI2oPbtDv6Ve"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train model "
      ],
      "metadata": {
        "id": "Tr9Bo_E5sp5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Recall,Precision"
      ],
      "metadata": {
        "id": "lqfQ3dZ0ERX9"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "binary_cross_loss = tf.losses.BinaryCrossentropy()\n",
        "opt = tf.keras.optimizers.Adam(1e-4) \n",
        "\n",
        "checkpoint_dir = 'training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
        "checkpoint = tf.train.Checkpoint(opt=opt, siamese_model=siamese_model)"
      ],
      "metadata": {
        "id": "A8ZzSLFupY3E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_Step(batch):\n",
        "    with tf.GradientTape() as tape:    \n",
        "        X = batch[:2]\n",
        "        y = batch[2]\n",
        "        yhat = siamese_model(X, training=True)\n",
        "        loss = binary_cross_loss(y, yhat)\n",
        "    print(loss)    \n",
        "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
        "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
        "    return loss"
      ],
      "metadata": {
        "id": "0_rsBldiEZXE"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train(data, EPOCHS):\n",
        "    \n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
        "        progbar = tf.keras.utils.Progbar(len(data))\n",
        "        r = Recall()\n",
        "        p = Precision()\n",
        "  \n",
        "        for idx, batch in enumerate(data):\n",
        "            loss = train_Step(batch)\n",
        "            yhat = siamese_model.predict(batch[:2])\n",
        "            r.update_state(batch[2], yhat)\n",
        "            p.update_state(batch[2], yhat) \n",
        "            progbar.update(idx+1)\n",
        "        print(\"train_loss\",loss.numpy(),\"Recall\",r.result().numpy(),'Precision', p.result().numpy())\n",
        "        \n",
        "     \n",
        "        if epoch % 5 == 0: \n",
        "            checkpoint.save(file_prefix=checkpoint_prefix)"
      ],
      "metadata": {
        "id": "Irr46OwjEea8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS =10\n",
        "Train(train_data, EPOCHS)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUaDL3bNpmCL",
        "outputId": "49249f96-1ede-4a54-9fc3-fbcf84d568da"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1/10\n",
            "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "Tensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "26/27 [===========================>..] - ETA: 0sTensor(\"binary_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
            "27/27 [==============================] - 71s 353ms/step\n",
            "train_loss 0.0006839564 Recall 0.9766355 Precision 0.88559324\n",
            "\n",
            " Epoch 2/10\n",
            "27/27 [==============================] - 70s 311ms/step\n",
            "train_loss 0.000536924 Recall 0.99512196 Precision 0.96682465\n",
            "\n",
            " Epoch 3/10\n",
            "27/27 [==============================] - 68s 311ms/step\n",
            "train_loss 0.00043502217 Recall 0.99033815 Precision 0.9855769\n",
            "\n",
            " Epoch 4/10\n",
            "27/27 [==============================] - 69s 310ms/step\n",
            "train_loss 0.0012850091 Recall 0.99523807 Precision 0.9905213\n",
            "\n",
            " Epoch 5/10\n",
            "27/27 [==============================] - 63s 321ms/step\n",
            "train_loss 6.7719564e-05 Recall 1.0 Precision 0.9954338\n",
            "\n",
            " Epoch 6/10\n",
            "27/27 [==============================] - 67s 321ms/step\n",
            "train_loss 0.0024731914 Recall 1.0 Precision 0.9855769\n",
            "\n",
            " Epoch 7/10\n",
            "27/27 [==============================] - 61s 313ms/step\n",
            "train_loss 0.003509506 Recall 0.9858491 Precision 0.99523807\n",
            "\n",
            " Epoch 8/10\n",
            "27/27 [==============================] - 66s 311ms/step\n",
            "train_loss 4.31588e-06 Recall 1.0 Precision 1.0\n",
            "\n",
            " Epoch 9/10\n",
            "27/27 [==============================] - 62s 310ms/step\n",
            "train_loss 0.0021477202 Recall 0.9954338 Precision 1.0\n",
            "\n",
            " Epoch 10/10\n",
            "27/27 [==============================] - 65s 306ms/step\n",
            "train_loss 0.265034 Recall 0.99019605 Precision 0.9950739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recall=tf.keras.metrics.Recall()\n",
        "precision=tf.keras.metrics.Precision()\n",
        "\n",
        "for test_input, test_val, y_true in test_data.as_numpy_iterator():\n",
        "    yhat = siamese_model.predict([test_input, test_val])\n",
        "    recall.update_state(y_true, yhat)\n",
        "    precision.update_state(y_true,yhat) \n",
        "\n",
        "print(recall.result().numpy(), precision.result().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5PQarheDWBw",
        "outputId": "32b0de95-7169-4b83-80d3-764141bce64c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9892473 0.9892473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "siamese_model.save('my_model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-8cWk5w6WBg",
        "outputId": "b16a391f-142b-4e57-8f90-63c3c3808494"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test Real time "
      ],
      "metadata": {
        "id": "e3VVJYdz_7DO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('my_model.h5', \n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBrdmg0aF8UH",
        "outputId": "e30821a2-7c90-44a1-ea07-3e1bfc0df684"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    }
  ]
}